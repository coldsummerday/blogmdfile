
 首先,querySet对象在__getitem__方法中实现调用fetch all,如果cache为空,用list(self._iterable_class(self))方法获取到cache,然后返回响应的对象.在此更新的过程中,去根据queryset的属性(执行不同的查询方法会设置不同的queryset属性)编译sql语句,执行sql并取回,结果集.


##1.get_item(self,k):

```python
    def __getitem__(self, k):
        """Retrieve an item or slice from the set of results."""
        if not isinstance(k, (int, slice)):
            raise TypeError
        assert ((not isinstance(k, slice) and (k >= 0)) or
                (isinstance(k, slice) and (k.start is None or k.start >= 0) and
                 (k.stop is None or k.stop >= 0))), \
            "Negative indexing is not supported."

        if self._result_cache is not None:
            return self._result_cache[k]

        if isinstance(k, slice):
            qs = self._chain()
            if k.start is not None:
                start = int(k.start)
            else:
                start = None
            if k.stop is not None:
                stop = int(k.stop)
            else:
                stop = None
            qs.query.set_limits(start, stop)
            return list(qs)[::k.step] if k.step else qs

        qs = self._chain()
        qs.query.set_limits(k, k + 1)
        qs._fetch_all()
        return qs._result_cache[0]
```

_fetch_all方法:

```python
    def _fetch_all(self):
        if self._result_cache is None:
            self._result_cache = list(self._iterable_class(self))
        if self._prefetch_related_lookups and not self._prefetch_done:
            self._prefetch_related_objects()
```


而_iterable_class 为一个ModelIterable对象,其__iter__方法,()


##2.__iter__方法
在class ModelIterable(BaseIterable):

的__Iter__方法,真正去db中运行sql语句并执行取回结果,并返回一个个obj,变为list

```python
    def __iter__(self):
        queryset = self.queryset
        db = queryset.db
        #获取sql编译器,准备编译sql语句
        compiler = queryset.query.get_compiler(using=db)
        # Execute the query. This will also fill compiler.select, klass_info,
        # and annotations.
        #真正执行Sql取回结果
        results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)
        select, klass_info, annotation_col_map = (compiler.select, compiler.klass_info,
                                                  compiler.annotation_col_map)
        model_cls = klass_info['model']
        select_fields = klass_info['select_fields']
        model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1
        init_list = [f[0].target.attname
                     for f in select[model_fields_start:model_fields_end]]
        related_populators = get_related_populators(klass_info, select, db)
        for row in compiler.results_iter(results):
            obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end])
            if related_populators:
                for rel_populator in related_populators:
                    rel_populator.populate(row, obj)
            if annotation_col_map:
                for attr_name, col_pos in annotation_col_map.items():
                    setattr(obj, attr_name, row[col_pos])

            # Add the known related objects to the model, if there are any
            if queryset._known_related_objects:
                for field, rel_objs in queryset._known_related_objects.items():
                    # Avoid overwriting objects loaded e.g. by select_related
                    if field.is_cached(obj):
                        continue
                    pk = getattr(obj, field.get_attname())
                    try:
                        rel_obj = rel_objs[pk]
                    except KeyError:
                        pass  # may happen in qs1 | qs2 scenarios
                    else:
                        setattr(obj, field.name, rel_obj)

            yield obj

```

##3.总结

django orm这种"惰性查询"机制,一定程度上减少对sql的 io操作,减少了因为频繁io导致性能的开销


其实现机制是:在使用filter ,get等获取sql的操作时,其实只是对queryset类的一个属性更改(其内置了where,select,join等对象,用于设置sql不同部分),等待真正去获取queryset的iter的时候才真正去编译sql语句,如果queryset涉及到分片操作,则在sql中假如limit number的操作,来实现减少结果集的传输.









